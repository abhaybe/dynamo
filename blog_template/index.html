<html>
    <head>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
      },
      svg: {
        fontCache: 'global'
      }
    };
    </script>

        <link rel="shortcut icon" href="images/icon.ico" />
        <style type="text/css">
            body {
            	background-color: #f5f9ff;
            }

            /* Hide both math displays initially, will display based on JS detection */
             .mathjax-mobile, .mathml-non-mobile { display: none; }

             /* Show the MathML content by default on non-mobile devices */
             .show-mathml .mathml-non-mobile { display: block; }
             .show-mathjax .mathjax-mobile { display: block; }

            .content-margin-container {
            	display: flex;
            	width: 100%; /* Ensure the container is full width */
            	justify-content: left; /* Horizontally centers the children in the container */
            	align-items: center;  /* Vertically centers the children in the container */
            }
            .main-content-block {
            	width: 70%; /* Change this percentage as needed */
               max-width: 1100px; /* Optional: Maximum width */
            	background-color: #fff;
            	border-left: 1px solid #DDD;
            	border-right: 1px solid #DDD;
            	padding: 8px 8px 8px 8px;
            	font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;#"Avenir";
            }
            .margin-left-block {
            		font-size: 14px;
            		width: 15%; /* Change this percentage as needed */
            		max-width: 130px; /* Optional: Maximum width */
            		position: relative;
            		margin-left: 10px;
            		text-align: left;
            		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;#"Avenir";
            		padding: 5px;
            }
            .margin-right-block {
            		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;#"Avenir";
            		font-size: 14px;
            		width: 25%; /* Change this percentage as needed */
            		max-width: 256px; /* Optional: Maximum width */
            		position: relative;
            		text-align: left;
            		padding: 10px;  /* Optional: Adds padding inside the caption */
            }

            img {
            		max-width: 100%; /* Make sure it fits inside the container */
            		height: auto;
            		display: block;
            		margin: auto;
            }
            .my-video {
            		max-width: 100%; /* Make sure it fits inside the container */
            		height: auto;
            		display: block;
            		margin: auto;
            }
            /* Hide both video displays initially, will display based on JS detection */
             .vid-mobile, .vid-non-mobile { display: none; }

             /* Show the video content by default on non-mobile devices */
             .show-vid-mobile .vid-mobile { display: block; }
             .show-vid-non-mobile .vid-non-mobile { display: block; }

            a:link,a:visited
            {
            	color: #0e7862; /*#1367a7;*/
            	text-decoration: none;
            }
            a:hover {
            	color: #24b597; /*#208799;*/
            }

            h1 {
            	font-size: 18px;
            	margin-top: 4px;
            	margin-bottom: 10px;
            }

            table.header {
               font-weight: 300;
               font-size: 17px;
               flex-grow: 1;
            	width: 70%;
               max-width: calc(100% - 290px); /* Adjust according to the width of .paper-code-tab */
            }
            table td, table td * {
                vertical-align: middle;
                position: relative;
            }
            table.paper-code-tab {
                flex-shrink: 0;
                margin-left: 8px;
                margin-top: 8px;
                padding: 0px 0px 0px 8px;
                width: 290px;
                height: 150px;
            }

            .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
            	box-shadow:
            	        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            	        5px 5px 0 0px #fff, /* The second layer */
            	        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            	        10px 10px 0 0px #fff, /* The third layer */
            	        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
            	margin-top: 5px;
            	margin-left: 10px;
            	margin-right: 30px;
            	margin-bottom: 5px;
            }

            hr {
               height: 1px; /* Sets the height of the line to 1 pixel */
               border: none; /* Removes the default border */
               background-color: #DDD; /* Sets the line color to black */
             }

            div.hypothesis {
            	width: 80%;
            	background-color: #EEE;
            	border: 1px solid black;
            	border-radius: 10px;
            	-moz-border-radius: 10px;
            	-webkit-border-radius: 10px;
            	font-family: Courier;
            	font-size: 18px;
            	text-align: center;
            	margin: auto;
            	padding: 16px 16px 16px 16px;
            }

            div.citation {
               font-size: 0.8em;
               background-color:#fff;
               padding: 10px;
            	height: 200px;
             }

            .fade-in-inline {
            	position: absolute;
            	text-align: center;
            	margin: auto;
            	-webkit-mask-image: linear-gradient(to right,
            																		transparent 0%,
            																		transparent 40%,
            																		black 50%,
            																		black 90%,
            																		transparent 100%);
            	mask-image: linear-gradient(to right,
            															transparent 0%,
            															transparent 40%,
            															black 50%,
            															black 90%,
            															transparent 100%);
            	-webkit-mask-size: 8000% 100%;
            	mask-size: 8000% 100%;
            	animation-name: sweepMask;
            	animation-duration: 4s;
            	animation-iteration-count: infinite;
            	animation-timing-function: linear;
            	animation-delay: -1s;
            }

            .fade-in2-inline {
            		animation-delay: 1s;
            }

            .inline-div {
            		position: relative;
                display: inline-block; /* Makes both the div and paragraph inline-block elements */
                vertical-align: top; /* Aligns them at the top, you can adjust this to middle, bottom, etc., based on your needs */
                width: 50px; /* Optional: Adds space between the div and the paragraph */
            }
        </style>

        <title>DynaMO</title>
        <meta property="og:title" content="Dynamo" />
        <meta charset="UTF-8" />
    </head>

    <body>
        <div class="content-margin-container">
            <div class="margin-left-block"></div>
            <div class="main-content-block">
                <table class="header" align="left">
                    <tr>
                        <td colspan="4">
                            <span
                                style="
                                    font-size: 32px;
                                    font-family: 'Courier New', Courier,
                                        monospace; /* Adds fallbacks */
                                "
                                >Dynamic Mixture Optimization (DynaMO)</span
                            >
                        </td>
                    </tr>
                    <tr>
                        <td align="left">
                            <span style="font-size: 17px"
                                ><a href="your_website"
                                    >Abhay Bestrapalli</a
                                ></span
                            >
                        </td>
                        <td align="left">
                            <span style="font-size: 17px"
                                ><a href="your_partner's_website"
                                    >Gilford Ting</a
                                ></span
                            >
                        </td>
                    </tr>

                    <tr>
                        <td colspan="4" align="left">
                            <span style="font-size: 18px"
                                >Final project for 6.7960, MIT</span
                            >
                        </td>
                    </tr>
                </table>
            </div>
            <div class="margin-right-block"></div>
        </div>

        <div class="content-margin-container" id="intro">
            <div class="margin-left-block">
                <!-- table of contents here -->
                <div
                    style="
                        position: fixed;
                        max-width: inherit;
                        top: max(20%, 120px);
                    "
                >
                    <b style="font-size: 16px">Outline</b><br /><br />
                    <a href="#intro">Introduction</a><br /><br />
                    <a href="#bg">Background and Literature</a><br /><br />
                    <a href="#methods"
                        >Methodology</a
                    ><br /><br />
                    <a href="#analysis"
                        >Analysis and Results</a
                    ><br /><br />
                    <a href="#limitations"
                        >Limitations and Future Directions</a
                    ><br /><br />
                </div>
            </div>
            <div class="main-content-block">
                <!--You can embed an image like this:-->
                <!-- <img src="./images/your_image_here.png" width="512px" /> -->
            </div>
            <!-- <div class="margin-right-block">Caption for the image.</div> -->
        </div>

        <div class="content-margin-container" id="intro">
            <div class="margin-left-block"></div>
            <div class="main-content-block">
                <h1 style="font-size: 32px">Introduction</h1>
                <hr style="border-top: 1px solid #cccccc" />
                Large language models (LLMs) have revolutionized natural
                language processing by harnessing vast and diverse datasets
                during training. Modern LLMs are trained on trillions of tokens
                of data over several stages. These datasets span an array of
                domains and subdomains — from programming languages like Python
                and Java to specialized fields like legal documents, scientific
                literature, and creative writing. However, this diversity
                introduces a crucial challenge:
                <b>determining the optimal composition of training data.</b>
                Simply training on all available data can lead to
                inefficiencies, such as overemphasizing certain tasks or domains
                at the expense of others, and may fail to leverage the full
                potential of the model. For instance, one direct way this
                heuristic is universally applied is by splitting training into
                pre-training, with simpler and more diverse data, and
                fine-tuning, with task-specific and high-quality data.
                <br /><br />
                This challenge of choosing data mixtures is further compounded
                by insights from
                <b>neural scaling laws</b> which emphasize that both model size
                and dataset size must be scaled in tandem for optimal
                performance. It is, therefore, important, to these findings
                underscore the importance of deliberate, empirical strategies in
                curating training data mixtures rather than relying on ad hoc
                methods. The question of how to systematically identify and
                fine-tune the ideal blend of training data is thus an open and
                pressing problem in the field. <br /><br />

                Our work introduces
                <b>DynaMO (Dynamic Mixture Optimization)</b> — a framework that
                dynamically adjusts data mixture weights during fine-tuning.
                Unlike previous methods, which primarily focus on static or
                proxy-based optimization, DynaMO integrates the optimization
                process directly into the training loop. Our hypothesis is that
                this dynamic approach will lead to measurable improvements in
                training efficiency, uncover superior performance outcomes, and
                potentially reveal new principles governing data mixture
                optimization. <br /><br />
            </div>
            <!-- <div class="margin-right-block">
                Margin note that clarifies some detail #main-content-block for
                intro section.
            </div> -->
        </div>
        <div class="content-margin-container" id="bg">
            <div class="margin-left-block"></div>
            <div class="main-content-block">
                <h1 style="font-size: 32px">Background and Literature</h1>
                <hr style="border-top: 1px solid #cccccc" />

                The question of how to optimally mix different types of training
                data has been a persistent challenge in machine learning.
                Traditionally, researchers relied heavily on manual heuristics
                and static mixing strategies. The Llama 3.1 team's
                <a href="#ref_1">[1]</a> approach of prioritizing "high-quality"
                data in specific domains like mathematics and reasoning
                exemplifies this traditional methodology. However, this is very
                trial and error based and may not give the best result. To solve
                this, we draw inspiration from several rich areas of machine
                learning:
                <br />

                <h3 style="font-size: 20px">
                    1. Multi-armed Bandit (MAB) Theory
                </h3>

                Multi-armed bandit theory generally explores how to sample from
                a dataset with only limited information about its distribution.
                Classical MAB works <a href="#ref_2">[2]</a> provide frameworks
                for optimizing decisions under uncertainty - perfectly
                applicable to our dynamic mixing problem. Recent adaptations
                like contextual bandits <a href="#ref_3">[3]</a> have made these
                connections even more relevant.

                <h3 style="font-size: 20px">2. Curriculum Learning</h3>
                Our work shares deep connections with curriculum learning
                principles (Bengio et al., 2009). The core assumptions are
                similar:
                <ul>
                    <li>Tasks can be meaningfully ordered.</li>
                    <li>Learning transfers from simpler to complex tasks.</li>
                    <li>Training sequence impacts final performance.</li>
                </ul>
                <br /><br />

                There have been other attempts at mixture optimization and
                understanding data mixtures. Recent years have seen a surge in
                more sophisticated approaches.
                <b>DoReMi</b> <a href="#ref_4">[4]</a> introduced a particularly
                elegant solution using reference models to dynamically infer
                optimal mixture weights. The key insight was training smaller
                proxy models on different mixture combinations, then using their
                performance to predict optimal mixing strategies for larger
                models. This effectively transformed mixture weights from fixed
                hyperparameters into learnable parameters that could be
                optimized through a meta-learning approach. However, this
                approach needs predefined data mixtures and cannot be customized
                for finetuning datasets, or for more fine-graind division. It
                also assumes that data mixtures in small models generalize to
                larger models and datasets.<br /><br />
                Similarly, <b>Skill-it</b> <a href="#ref_5">[5]</a> approached
                the problem through the lens of prerequisite relationships,
                introducing a "skills graph" that maps dependencies between
                different training objectives. By modeling how different
                capabilities build upon each other, Skill-it can dynamically
                adjust data mixture weights based on the model's current skill
                proficiency and the natural progression of skill acquisition.
                This graph-based approach provides an interpretable framework
                for curriculum learning strategies. While powerful, this
                approach requires careful manual design of the skills graph and
                may not generalize well to domains where skill relationships are
                less clear.<br /><br />
            </div>
            <!-- <div class="margin-right-block">
                Margin note that clarifies some detail #main-content-block for
                intro section.
            </div> -->
        </div>
        <div class="content-margin-container" id="methods">
            <div class="margin-left-block"></div>
            <div class="main-content-block">
                <h1 style="font-size: 32px">Methodology</h1>
                <hr style="border-top: 1px solid #cccccc" />

                <h2 style="font-size: 24px">The Setup: Dataset and Model</h1>

                Optimizing data mixtures is an important issue for both
                pre-training and fine-tuning, with possibly different results
                given the difference in data quality in the two stages. However,
                we choose to focus on fine-tuning for several reasons:
                <ul>
                    <li>
                        Fine-tuning datasets are more customized, allowing us to
                        focus on specific types of data.
                    </li>
                    <li>
                        The subdomains of the dataset are typically already
                        clearly delineated, which allows us to avoid large
                        amounts of data preprocessing and analysis.
                    </li>
                    <li>
                        Overall, finetuning is much more effective given our
                        constraints in cost, compute, and time.
                    </li>
                </ul>

                We use the <b>AMPS Dataset</b> <a href="#ref_6">[6]</a> –
                specifically, we take a subset of all of the 6 domains in the
                Mathematica training set (algebra, geometry, calculus, counting
                and statistics, linear algebra, and number theory). We chose
                this dataset because it provided distinct domains that would
                require different skills/knowledge, but with some amount of
                transfer between domains (e.g. proficiency in algebra may be
                helpful in linear algebra). For our model, we use Meta’s LLama
                3.2 1B<a href="#ref_7">[7]</a>. The small size of this model
                makes it easy and effective to finetune cost-wise, while the
                advanced training and finetuning done on this model ensures that
                our model is a strong baseline while still having room for
                improvement due to the limitations of its smaller size.

                <h2 style="font-size: 24px">Methodology</h1>
<p>
Suppose our dataset contains $N$ domains, where each domain is represented by a dataset $D_i$. Our method introduces a new set of parameters into the training process – these are <em>domain weights</em> $w_1$ to $w_N$, used to select the specific domain whose dataset we sample a datapoint from (specifically, weight $w_i$ directly influences the chance that $D_i$ is selected).
</p>

<p>
DynaMO adjusts these domain weights during the training process – specifically, every $T$ training steps (we fixed $T=50$ for all our experiments), we perform a dynamic update using a custom reweighting policy. This is done by observing the structure of the $N$ different loss curves for each domain. The specific policies that we tested are summarized below:
</p>

<ul>
<li>Baseline policy – Uniform random sampling, where $w_i = 1$ (the reweighting policy is the identity function). In other words, the domain weights do not change.</li>
<li>Delta policy- We use the change in loss to update weights. The reasoning is explored in the next section.</li>
<li>Average policy – $L_{i, \text{avg}}$, the average of the previous 100 values of loss, is used to update weights. We explore this in more detail under Experiment 1.</li>
</ul>

<p>
To allow dynamic reweighting <em>during</em> finetuning/training, we adjusted the data loading process. Normally, domain weights would be used to subsample from a larger dataset and be passed in as a fixed dataset into the training process – because the nature of our method requires the sampling step to be done during training, we modify PyTorch's Dataset class as needed. The weights are stored internally to this class, and every time <strong>getitem</strong> is called on this custom Dataset class, a domain is sampled using these weights and a datapoint is sampled from that domain. This custom dataset also tracks losses across the domains – each domain maintains a length-100 sliding window that can be used to determine how the loss has evolved in the recent pass. Finally, each dataset instance also has its own <em>weight update policy</em> function, called every $T$ training steps, that describes how to update the domain weights based on the current weights and the loss windows for each domain.
</p>
            </div>
            <div class="margin-right-block">
                Margin note that clarifies some detail #main-content-block for
                intro section.
            </div>
        </div>

        <div class="content-margin-container" id="analysis">
            <div class="margin-left-block"></div>
            <div class="main-content-block">
                <h1 style="font-size: 32px">Analysis and Results</h1>
                <hr style="border-top: 1px solid #cccccc" />
                First, we tested different reweighting policies with $\alpha$ values of 0.1 and -0.1. The resulting loss curves were as follows:
                <img src="./images/lossalpha0.1.png"/>
                As we can see, there is not a significant difference between the curves – we attribute these fluctuations to noise occurring during the random sampling. We also visualize the underlying weights for one of these policies (all policies looked very similar/practically identical).
                <img src="./images/weightchange.png"/>
                Thus, in these cases the reweighting policy and loss curve form a feedback loop – because the loss curves for each domain evolve very similarly, the weights for each domain also change near-identically. Then, the model continues to sample equally from each domain and the loss curves change in the same way.<br><br>
                Motivated by this, we tried larger values of $\alpha$ (1, 10, 100) to make the difference between domains more pronounced and have the model do something different than just continuing to sample uniformly randomly. The resulting loss curve is as follows – we present only $\alpha$ = 1 because larger values of alpha only magnified our following results.
                <img src="./images/lossalpha1.png"/>
                <p>Again, there are no appreciable results. When looking at the weight change plots, the policies that consider average loss behave the same as before – all domains scale up equally in lockstep. For the policies considering <em>change</em> in loss (both upsampling and downsampling), however, we observe a more interesting phenomenon:</p>
                <img src="./images/weightupdates_best_withoutlier.png"/>
                <img src="./images/weightupdates_new_nooutlier.png"/>
                <p>
                    Here, one domain gets weighted down significantly while the other domain weights start to have more meaningful adjustments. We suspect that the downweighting of one domain occurs when it simply gets unlucky – the change in loss is maximally adversarial and makes it decrease the most out of all domains, which then causes it to be sampled less, <em>leaving the last two loss values in the window unchanged</em> – another runaway effect is observed. For the other domains, we see some changes that are at a larger scale than before – some of the domains have a definitive trend upwards. However, these results are not consistent across policies/differing values of alpha. See the following plot:
                </p>

                Here, the domains are essentially in a random order compared to before. Thus, we conclude that the evolution of these domain weights is largely the accumulation of noise, just on a higher scale than in previous runs.<br><br>

                The last thing we tested was initializing the domain weights to be non-uniform, by making one of them slightly higher than the others. This simply induced another similar runaway effect, where the domain whose weight was initially increased started growing much faster than the other weights and ended up being the only domain sampled.
            </div>
            <!-- <div class="margin-right-block">
                Margin note that clarifies some detail #main-content-block for
                intro section.
            </div> -->
        </div>

        <div class="content-margin-container" id="limitations">
            <div class="margin-left-block"></div>
            <div class="main-content-block">
                <h1 style="font-size: 32px">Limitations and Future Directions</h1>
                <hr style="border-top: 1px solid #cccccc" />
                <p>
                    Although our method did not produce significant results on
                    the model and datasets we experimented with, we have gained
                    a much better understanding of the problem and suggest many
                    promising future directions.
                </p>
                <p>
                    Firstly, we chose to finetune on subsets of a specific
                    domain rather than finetune on domains that were very
                    different. For example, having domains of English vs. code
                    vs. Spanish would prove to be very different problems for
                    the model, and the model might learn a more effective set of
                    weights -- it's possible that many of the math domains were
                    too similar (e.g. math formatting, tone of the problem
                    statement, etc.) With a larger and more diverse dataset, we
                    might observe more meaningful results.
                </p>
                <p>
                    Furthermore, we used a 1B parameter LLM because of
                    computational constraints -- at this stage, the model is
                    likely not good enough to learn the nuances between
                    different data domains. We tested the output of the
                    generated models, and this is what they often looked like:
                </p>
                <p>Question: Solve for x: 2x + 3 = 11</p>
                <p>
                    Generated Answer:
                    <pre class="no-mathjax">$$$fracfracrightfracfracright$\$\$sqrt$$\$\\$\$$\$\$\$\$\$\$$$$\$\$$$\\$$\$\,3$right$\\left{${3$\{$\$$$$\right{right+{{right{{{2\{22+{1{2{22{2\{right3right\22}2end2$2{$right\$end$\right{end$\2{\+\3{{\3right\{\{\\{{\{{-\2right13right34{\{right$2{,\2right\1\\{0\{{{\end{2,2}{1right{$&\\11right\2{{&{end{end{}\2\\{end$end$endright22{\{end{\\
                    \end\rightrightend02\2left32{\\endright\\\right{\{\\{\\end\\\4rightend\\right\\\\{2\\2\2end22\end2\rightright22{\2endend\\\22{\2end5\end2{1\{\\{\right2{2\\\{\\{2,2{\{4\15\{end\\\\\}\\\\5\{\&\{\3\\{\5&24\{\4{2\\{\3\0\&\\\1\\2\\\5\\{\\352\\\\3\\\\{\\\\6\\\\2\\2rightend5\{\\,26\\\2\5\\\\\4\2\2\\\5\\\2\5}2\\\\\2{{{&^\62\\{\end5002{12{&2\22222{5,end65\\\,52155{122562\</pre>
                </p>
                <p>
                    From this, we can see that the model is only really learning
                    what tokens are likely to occur in a formatted math problem
                    – it’s predicting lots of numbers and formatting keywords
                    instead of any coherent output. Because of its limited size,
                    it only got a general idea of what math output is supposed
                    to look like, and is not actually learning the underlying
                    concepts. Under this lens, it makes sense that the different
                    reweighting policies were all effectively equivalent – our
                    small model was not able to understand the difference
                    between different domains because it was still learning the
                    higher-level structure of math-formatted text. If possible,
                    we would run this using a much larger model with stronger
                    baseline math capabilities – we suspect that once the model
                    is able to glean more of the nuances in the data, the
                    mixture reweighting will prove to be more effective.
                </p>
                <p>
                    Our experiments also proved that the scale of the weight
                    updates is also a crucial aspect of the reweighting policy –
                    in our results, we clearly found that an $\alpha$ of 0.1 vs 1
                    crossed some boundary that induced different behavior. With
                    more compute available, we would do a more fine-grained
                    search on $\alpha$ and find the most significant value(s)
                    within this interval. Furthermore, this scale is likely
                    specific to our task – in a different training/finetuning
                    environment with a different loss scale and different
                    domains, the exact value of $\alpha$ that is optimal for weight
                    updates would likely be very different. One possible
                    approach to finding this value would be to develop a proxy
                    model that is able to adjust $\alpha$ as training evolves –
                    this could be some simple meta-learning approach or as
                    complicated as a mini neural network.
                </p>
                <p>
                    Lastly, we operated in the realm of finetuning vs
                    pretraining. It’s possible that with pretraining, mixture
                    reweighting could look very different – the model might need
                    to learn from more general knowledge before it is able to
                    fully understand the information from a more specific domain
                    (e.g. English before code).
                </p>
                <p>
                    Overall, we’re optimistic about bringing this method to a
                    larger scale of LLM development – there are many exciting
                    research directions that could bring us closer to truly
                    adaptive curriculum learning.
                </p>
            </div>
            <!-- <div class="margin-right-block">
                Margin note that clarifies some detail #main-content-block for
                intro section.
            </div> -->
        </div>

        <div class="content-margin-container" id="citations">
            <div class="margin-left-block"></div>
            <div class="main-content-block">
                <div class="citation" id="references" style="height: auto">
                    <br />
                    <span style="font-size: 16px">References:</span><br /><br />
                    <a id="ref_1"></a>[1]
                    <a href="https://arxiv.org/abs/2407.21783"
                        >The Llama 3 Herd of Models</a
                    >, Meta, 2024<br /><br />
                    <a id="ref_2"></a>[2]
                    <a href="https://arxiv.org/abs/1911.07676"
                        >Learning with Good Feature Representations...</a
                    >, Lattimore and Szepesvári, 2020, for example<br /><br />

                    <a id="ref_3"></a>[3]
                    <a href="https://arxiv.org/abs/1905.01435"
                        >Tight Regret Bounds for Infinite...</a
                    >, Li et al., 2021<br /><br />

                    <a id="ref_4"></a>[4]
                    <a href="https://arxiv.org/abs/2305.10429"
                        >DoReMi: Optimizing Data Mixtures Speeds Up Language
                        Model Pretraining</a
                    >, Xie et al., 2023<br /><br />
                    <a id="ref_5"></a>[5]
                    <a href="https://arxiv.org/abs/2307.14430"
                        >Skill-it! A Data-Driven Skills Framework for...</a
                    >, Chen et al., 2023<br /><br />

                    <a id="ref_6"></a>[6]
                    <a href="https://github.com/hendrycks/math"
                        >Measuring Mathematical Problem Solving With the MATH
                        Dataset</a
                    >, Hendrycks et al., 2021<br /><br />

                    <a id="ref_7"></a>[7] We used the
                    <a href="https://huggingface.co/unsloth/Llama-3.2-1B"
                        >Unslouth Huggingface Repo.</a
                    ><br /><br />
                </div>
            </div>
            <div class="margin-right-block">
                <!-- margin notes for reference block here -->
            </div>
        </div>
    </body>
</html>
